{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split \n",
    "# from sklearn import datasets, tree\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "%matplotlib inline\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio  # me permite dibujar en un notebook\n",
    "pio.renderers.default = \"notebook\"  # me permite dibujar en un notebook\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "import requests\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load/write labels and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_start_label='Parameter'\n",
    "Parameter_data_rows = ['Unit','HighL','LowL','Tests#','Patterns']\n",
    "HardBinDictName='HardBinName'\n",
    "SoftBinDictName='SoftBinName'\n",
    "header_rows_drop = 4\n",
    "datatypes_per_unit = {\n",
    "    'VOLTS':'float64',\n",
    "    'Ohms':'float64',\n",
    "    'V':'float64',\n",
    "    'uSECONDS':'float64',\n",
    "    'mAMPS':'float64',\n",
    "    ' ':'float64',\n",
    "    'code':'int64',\n",
    "    'C':'float64',\n",
    "    'LSB':'float64',\n",
    "    'deg':'float64',\n",
    "    'PF':'float64',\n",
    "    'KHERTZ':'float64',\n",
    "    'MHERTZ':'float64',\n",
    "    'KkHz':'float64',\n",
    "    '%':'float64',\n",
    "    'uAMPS':'float64',\n",
    "    'nnA':'float64',\n",
    "    'nAMPS':'float64'}\n",
    "testdatacols=[' SBIN','HBIN','DIE_X','DIE_Y','SITE','TIME','TOTAL_TESTS','LOT_ID','WAFER_ID']\n",
    "confdict={'data_start_label':data_start_label,'Parameter_data_rows':Parameter_data_rows,'testdatacols':testdatacols,'HardBinDictName':HardBinDictName,'SoftBinDictName':SoftBinDictName,'datatypes_per_unit':datatypes_per_unit}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv\n",
    "generate df with data\n",
    "generate HardBinDict\n",
    "generate SoftBinDict\n",
    "generate general_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (_file_location, _confdict):\n",
    "    _rawdf = pd.read_csv(_file_location)  # carga csv\n",
    "    #future adding exceptions for cases like no string match as \"Parameter\" to handle and track code breakdown\n",
    "    _data_start_col_value=(_rawdf.iloc[:,0]==_confdict.get('data_start_label')).idxmax()+1  # search for label in table data start\n",
    "    _df = pd.read_csv(_file_location, header=_data_start_col_value, index_col=_confdict.get('data_start_label'))  # load table data from csv into df\n",
    "    _df.drop(columns=_df.columns[-1], axis=1, inplace=True) #extra column without data\n",
    "\n",
    "    #separate testdata and parameter data (might get input to make this optional)\n",
    "    _dftestdata = _df[_confdict.get('testdatacols')]\n",
    "    _df.drop(columns=_confdict.get('testdatacols'), inplace=True)\n",
    "    _dfpardata=_df.loc[_confdict.get('Parameter_data_rows')]\n",
    "    _df.drop(_confdict.get('Parameter_data_rows'), inplace=True)\n",
    "    _df.reset_index(drop=True)\n",
    "    #_dfpardata.loc['Unit'].replace(confdict.get('datatypes_per_unit'))\n",
    "\n",
    "    # \n",
    "    _rawdf = _rawdf.head(_data_start_col_value-1)  # drop table data\n",
    "    _rawdf = _rawdf.tail(-header_rows_drop)  # drop 4 rows from the header\n",
    "    _HardBinDict = (_rawdf[_rawdf.iloc[:,0]==_confdict.get('HardBinDictName')].iloc[:,[1,2]])\n",
    "    _HardBinDict = _HardBinDict.set_index(_HardBinDict.iloc[:, 0]).iloc[:,1]\n",
    "    _HardBinDict = _HardBinDict.to_dict()\n",
    "    _SoftBinDict = (_rawdf[_rawdf.iloc[:,0]==_confdict.get('SoftBinDictName')].iloc[:,[1,2]])\n",
    "    _SoftBinDict = _SoftBinDict.set_index(_SoftBinDict.iloc[:, 0]).iloc[:,1]\n",
    "    _SoftBinDict = _SoftBinDict.to_dict()\n",
    "    _rawdf = _rawdf[(_rawdf.iloc[:,0]!=_confdict.get('HardBinDictName'))&(_rawdf.iloc[:,0]!=_confdict.get('SoftBinDictName'))]  # drop softbin and hardbin\n",
    "    _rawdf.dropna(how='all')\n",
    "    _general_data = _rawdf.iloc[:,[0,1]]  # global data extracted by position\n",
    "    _general_data = _general_data.set_index(_general_data.iloc[:, 0]).iloc[:,1]\n",
    "    _general_data = _general_data.to_dict()\n",
    "\n",
    "    # input corrections\n",
    "    _dfpardata['HSR_SMM ANGLE_D1']['Unit'] = 'deg'  # unit is \"code\" and should be \"deg\"\n",
    "    _dfpardata['HSR_SMM ANGLE_D2']['Unit'] = 'deg'  # unit is \"code\" and should be \"deg\"\n",
    "    _df = _df.replace(r'^\\s*$', '99999999', regex=True)  # if a chip blows, no further testing is done and a space char is placed instead of a value, cannot use np.NaN for int dtypes\n",
    "\n",
    "    _coldtypes=_dfpardata.loc['Unit'].replace(_confdict.get('datatypes_per_unit')).fillna('float64').to_dict()  # if no unit is stated defaults to float dtype as there are many non integers\n",
    "    _df = _df.astype(_coldtypes)\n",
    "\n",
    "    return (_df, _general_data,_dfpardata,_dftestdata, _HardBinDict, _SoftBinDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location1 = \"C:/Users/ggrinberg/Downloads/QR6129X1.csv\"\n",
    "file_location2 = \"C:/Users/ggrinberg/Downloads/QH6129X2.csv\"\n",
    "file_location3 = \"C:/Users/ggrinberg/Downloads/QR6129X3.csv\"\n",
    "file_location4 = \"C:/Users/ggrinberg/Downloads/QH6129X4.csv\"\n",
    "(df1, general_data1 ,dfpardata1, dftestdata1, HardBinDict, SoftBinDict) = load_data (file_location1, confdict)\n",
    "(df2, general_data2 ,dfpardata2, dftestdata2, HardBinDict, SoftBinDict) = load_data (file_location2, confdict)\n",
    "(df3, general_data3 ,dfpardata3, dftestdata3, HardBinDict, SoftBinDict) = load_data (file_location3, confdict)\n",
    "(df4, general_data4 ,dfpardata4, dftestdata4, HardBinDict, SoftBinDict) = load_data (file_location4, confdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank cells filled with99999999.0\n",
      "parameter data are not equal among different tests as shown here:False\n",
      "there are 87 of 862 measurements which are not in the 4 datasets, most are temperature related, check with pato \n"
     ]
    }
   ],
   "source": [
    "print(f\"blank cells filled with{df3['SENT Trigger Threshold L Code 0_D1']['PID-120']}\")  # check how an empty cell is filled\n",
    "print(f\"parameter data are not equal among different tests as shown here:{dfpardata1.equals(dfpardata2)}\")  # values and size not equal\n",
    "measures = Counter(dfpardata1.columns.to_list()+dfpardata2.columns.to_list()+dfpardata3.columns.to_list()+dfpardata4.columns.to_list())\n",
    "result = [_key for _key, _value in measures.items () if _value != 4]\n",
    "print(f\"there are {len(result)} of {len(measures)} measurements which are not in the 4 datasets, most are temperature related, check with pato \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediciones fuera de limites para df1\n",
      "Secondary Temp Sensor (25C)_D1    136\n",
      "Secondary Temp Sensor (25C)_D2    136\n",
      "Primary Temp Sensor (25C)_D2        6\n",
      "HSR_SMM_D2                          5\n",
      "HSR_SMM_D1                          4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Lims1=dfpardata1.loc[['LowL','HighL']].astype('float')\n",
    "faulted_by_param = (df1.gt(Lims1.loc['HighL'], axis=1) | df1.lt(Lims1.loc['LowL'], axis=1))\n",
    "print('mediciones fuera de limites para df1')\n",
    "print(faulted_by_param.sum()[faulted_by_param.any()].sort_values(ascending=False).head(10))  # secondary sensor has ill defined thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediciones fuera de limites para df2\n",
      "IWRevZen_D2    69\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Lims2=dfpardata2.loc[['LowL','HighL']].astype('float')\n",
    "faulted_by_param = (df2.gt(Lims2.loc['HighL'], axis=1) | df2.lt(Lims2.loc['LowL'], axis=1))\n",
    "print('mediciones fuera de limites para df2')\n",
    "print(faulted_by_param.sum()[faulted_by_param.any()].sort_values(ascending=False).head(10))  # secondary sensor has ill defined thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediciones fuera de limites para df3\n",
      "Secondary Temp Sensor (25C)_D1    126\n",
      "Secondary Temp Sensor (25C)_D2    126\n",
      "HSR_SMM_D2                          5\n",
      "HSR_SMM_D1                          4\n",
      "Primary Temp Sensor (25C)_D1        2\n",
      "Intra Channel HP3 Fine_D1.1         2\n",
      "Intra Channel HP5 Fine_D1.1         2\n",
      "Intra Channel HP4 Coarse_D2.1       2\n",
      "Intra Channel HP4 Coarse_D1.1       2\n",
      "Intra Channel HP4 Fine_D2.1         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Lims3=dfpardata3.loc[['LowL','HighL']].astype('float')\n",
    "faulted_by_param = (df3.gt(Lims3.loc['HighL'], axis=1) | df3.lt(Lims3.loc['LowL'], axis=1))\n",
    "print('mediciones fuera de limites para df3')\n",
    "print(faulted_by_param.sum()[faulted_by_param.any()].sort_values(ascending=False).head(10))  # secondary sensor has ill defined thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediciones fuera de limites para df4\n",
      "IWRevZen_D2                      64\n",
      "Intra Channel HP1 Coarse_D2.1     2\n",
      "Intra Channel HP4 Fine_D2.1       2\n",
      "Intra Channel HP4 Fine_D1.1       2\n",
      "Intra Channel HP3 Coarse_D2.1     2\n",
      "Intra Channel HP3 Coarse_D1.1     2\n",
      "Intra Channel HP3 Fine_D2.1       2\n",
      "Intra Channel HP3 Fine_D1.1       2\n",
      "Intra Channel HP2 Coarse_D2.1     2\n",
      "Intra Channel HP2 Coarse_D1.1     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Lims4=dfpardata4.loc[['LowL','HighL']].astype('float')\n",
    "faulted_by_param = (df4.gt(Lims4.loc['HighL'], axis=1) | df4.lt(Lims4.loc['LowL'], axis=1))\n",
    "print('mediciones fuera de limites para df4')\n",
    "print(faulted_by_param.sum().sort_values(ascending=False).head(10)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
